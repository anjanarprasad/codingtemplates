{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFEBcqaIjv53"
      },
      "outputs": [],
      "source": [
        "!pip install -q pandas numpy matplotlib seaborn scikit-learn missingno category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UpYQD0blj8NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded[list(uploaded.keys())[0]]))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NKR1MljskCCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.describe(include='all')\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "38OVimRFkJFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualize missing values"
      ],
      "metadata": {
        "id": "vAy_i8Vl9gVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msno.matrix(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ET8NGCjJkRAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "imputation"
      ],
      "metadata": {
        "id": "Lh0buAxZ9c50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[num_cols] = imputer.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "Polpk8W8kUWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "isolation forest"
      ],
      "metadata": {
        "id": "BxpwsSnr9kGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iso = IsolationForest(contamination=0.01)\n",
        "yhat = iso.fit_predict(df[num_cols])\n",
        "\n",
        "df = df[yhat != -1]\n",
        "outlier_count = np.sum(outlier_preds == -1)\n",
        "print(f\"Number of outliers detected: {outlier_count}\")"
      ],
      "metadata": {
        "id": "OTrkLFb-kbPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "one hot encoder"
      ],
      "metadata": {
        "id": "FiUHDiNp9mIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "le = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    if df[col].nunique() == 2:\n",
        "        df[col] = le.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "HIwjvOVxkkcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, drop_first=True)"
      ],
      "metadata": {
        "id": "0AOQu4jXkprh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "OXBbK7MCks34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'date' in df.columns:\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['day'] = df['date'].dt.day\n",
        "    df['weekday'] = df['date'].dt.weekday"
      ],
      "metadata": {
        "id": "yAdeAGlnkvoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'your_target_column_here'  # ðŸ‘ˆ change this!\n",
        "X = df.drop(target, axis=1)\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ac5oiBwqkzC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "automated preprocessing"
      ],
      "metadata": {
        "id": "CjR0IfomAR4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pycaret\n",
        "\n",
        "from pycaret.classification import setup, compare_models\n",
        "\n",
        "\n",
        "setup(data=df, target=target, session_id=123)\n",
        "best = compare_models()\n"
      ],
      "metadata": {
        "id": "NL55zR7wk2iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputing Missing Values in Categorical Columns\n"
      ],
      "metadata": {
        "id": "2atii500B5mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])"
      ],
      "metadata": {
        "id": "k_JLZ965k77-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity Detection (Remove Redundant Features)\n"
      ],
      "metadata": {
        "id": "MywL5gkTCAkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "corr_matrix = df.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "high_corr_cols = [col for col in upper.columns if any(upper[col] > 0.9)]\n",
        "\n",
        "print(\"Highly correlated columns to consider dropping:\", high_corr_cols)\n",
        "\n",
        "# Optional: Drop them\n",
        "df.drop(columns=high_corr_cols, inplace=True)"
      ],
      "metadata": {
        "id": "Oqqd6caAB8Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Class Imbalance (with SMOTE)"
      ],
      "metadata": {
        "id": "Rm5rlJVHCGFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn --quiet\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Split features and target first (if not already done)\n",
        "X = df.drop('target_column', axis=1)  # replace 'target_column'\n",
        "y = df['target_column']\n",
        "\n",
        "# Balance the classes using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Optional: confirm new class counts\n",
        "pd.Series(y_resampled).value_counts()\n"
      ],
      "metadata": {
        "id": "25PixQ5wCDMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Scikit-learn Pipelines (for clean, chainable preprocessing)"
      ],
      "metadata": {
        "id": "3eF3RgflCMAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Separate numeric and categorical\n",
        "num_cols = X.select_dtypes(include=np.number).columns\n",
        "cat_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "# Define transformers\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine them\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipeline, num_cols),\n",
        "    ('cat', cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "# Apply transformation\n",
        "X_transformed = preprocessor.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "A6-DIuwfCJBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automated Feature Selection (SelectKBest)\n"
      ],
      "metadata": {
        "id": "M6csPm2GCRrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Keep top 10 features (you can change this number)\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_selected = selector.fit_transform(X_transformed, y_resampled)\n",
        "\n",
        "# To see which features were selected:\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "selected_feature_names = np.array(preprocessor.get_feature_names_out())[selected_indices]\n",
        "print(\"Top selected features:\", selected_feature_names)"
      ],
      "metadata": {
        "id": "JOs-8MDaCOi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hyUPdwc8C2vy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}